# 1.近似最近邻搜索

​	除了暴力搜索能完美的搜索出最相邻，所有的搜索算法只能在速度和质量还有内存上做一个权衡，这些算法也被称为近似最相邻（Approximate Nearest Neighbor）。

## 1.1 k-means和Faiss

![image-20250319135954556](C:\Users\26344\AppData\Roaming\Typora\typora-user-images\image-20250319135954556.png)

k-means算法的基本步骤：

1. **随机**选择 k 个初始聚类中心。
2. 将每个数据点分配到最近的聚类中心。
3. 计算每个聚类的新中心。
4. 重复步骤 2 和 3，直到聚类中心不再改变或达到最大迭代次数。

但是有一个问题，可能查询向量聚类A的中心最近，但实际上离聚类B里面的某个向量最近。为了解决搜索时可能存在的遗漏问题，可以将搜索范围动态调整，例如当 nprobe = 1 时，只搜索最近的一个聚类中心，当 nprobe = 2 时，搜索最近的两个聚类中心，根据实际业务的需求调整 nprobe 的值。

​	聚类算法的**维度灾难**：**随着维度的增加，数据点之间的距离会呈指数级增长**。一个 128 维的向量，需要维护 2^64 个聚类中心才能维持不错的量化结果，但这样的码本存储大小已经超过维护原始向量的内存大小了。

​	Faiss与上类似：

![image-20250319140454583](C:\Users\26344\AppData\Roaming\Typora\typora-user-images\image-20250319140454583.png)

## 1.2 Product Quantization

​	解决聚类方法维度灾难的方法：是**将向量分解为多个子向量**，然后对每个子向量独立进行量化，比如将 128 维的向量分为 8 个 16 维的向量，然后在 8 个 16 维的子向量上分别进行聚类，因为 16 维的子向量大概只需要 256 个聚类中心就能得到还不错的量化结果，所以就可以将码本的大小从 2^64 降低到 8 * 256 = 2048 个聚类中心，从而降低内存开销。

而将向量进行编码后，也将得到 8 个编码值，将它们拼起来就是该向量的最终编码值。等到使用的时候，只需要将这 8 个编码值，然后分别在 8 个子码本中搜索出对应的 16 维的向量，就能将它们使用笛卡尔积的方式组合成一个 128 维的向量，从而得到最终的搜索结果。这也就是乘积量化（Product Quantization）的原理。![image-20250319141150355](C:\Users\26344\AppData\Roaming\Typora\typora-user-images\image-20250319141150355.png)

​	PQ算法的唯一缺点是搜索质量下降，所有算法都是在**内存、速度和质量**上做一个权衡。

## 1.3 HNSW

​	分层导航小世界算法唯一的缺点是占用内存大。

![image-20250319141735116](C:\Users\26344\AppData\Roaming\Typora\typora-user-images\image-20250319141735116.png)

## 1.4 LSH

​	局部敏感哈希（Locality Sensitive Hashing）使用一组哈希函数将相似向量映射到“桶”中，从而使相似向量具有相同的哈希值。这样，就可以通过比较哈希值来判断向量之间的相似度。

![image-20250319141848610](C:\Users\26344\AppData\Roaming\Typora\typora-user-images\image-20250319141848610.png)

### 1.4.1 Random Projection for LSH 随机投影

​	在高维空间中，数据点之间的距离往往非常稀疏，数据点之间的距离会随着维度的增加呈指数级增长。导致计算出来的桶非常多，最极端的情况是每个桶中就一个向量，并且计算速度非常慢。所以实际上在实现 LSH 算法的时候，会考虑使用随机投影的方式，将高维空间的数据点投影到低维空间，从而减少计算的时间和提高查询的质量。

随机投影背后的基本思想是使用随机投影矩阵将高维向量投影到低维空间中。创建一个由随机数构成的矩阵，其大小将是所需的目标低维值。然后，计算输入向量和矩阵之间的点积，得到一个被投影的矩阵，它比原始向量具有更少的维度但仍保留了它们之间的相似性。

当我们查询时，使用**相同的投影矩阵**将查询向量投影到低维空间。然后，将投影的查询向量与数据库中的投影向量进行比较，以找到最近邻居。由于数据的维数降低了，搜索过程比在整个高维空间中搜索要快得多。

其基本步骤是：

1. 从高维空间中**随机**选择一个超平面，将数据点投影到该超平面上。
2. 重复步骤 1，选择多个超平面，将数据点投影到多个超平面上。
3. 将多个超平面的投影结果组合成一个向量，作为低维空间中的表示。
4. 使用哈希函数将低维空间中的向量映射到哈希桶中。