### 1. ==什么是Instruct GPT==

Instruct GPT核心技术是RLHF：SFT + RM + PPO。

ChatGPT = InstructGPT的核心技术 + 针对对话的优化训练。

### 2. ==什么是自我一致性采样==

我们不只向模型要一个答案，而是让它用**不同的方法、不同的思路**去解答同一个问题好几次。这通常通过在解码时引入一定的随机性（例如，使用较高的`temperature`参数）来实现，投票选出最一致的答案。

### 3. ==什么是自动提示工程师技术？==



### 4.==思维链是一种离散式提示学习==

“离散”（Discrete）这个词是相对于“连续”（Continuous）而言的。在提示学习的领域里，区分二者的关键在于**提示本身是由什么构成的**：



**离散式提示** 

- **形式是自然语言**：提示是由**单词、短语和句子**构成的。这些都是**离散的、独立的单元（Tokens）**。你不能用“半个词”或者“1.5个句子”来构成提示。每个词都是一个确定的、不可再分的实体。
- **构建方式是人工设计或搜索**：这些提示要么是人类专家（提示工程师）手动编写和优化的，要么是通过像APE这样的技术从一个巨大的、由自然语言构成的候选池中搜索出来的。整个过程是在一个离散的文本空间里进行的。

**思维链（CoT）完全符合这些特征。** 它的提示，无论是“让我们一步步思考”这句话，还是具体的解题示例，都是由人类可读的、离散的单词和句子组成的。

**连续式提示** 

为了更好地理解“离散”，我们来看看它的反面——“连续式提示”，也常被称为“软提示”（Soft Prompting）或“提示调优”（Prompt Tuning）。

- **形式是数字向量**：这种提示**不是自然语言**，而是一串**可训练的、连续的数字向量（Embeddings）**。你可以把它想象成一组模型才能理解的“神秘代码”。
- **构建方式是梯度下降**：这些“软提示”向量是通过在训练数据上进行梯度下降来直接“学习”和优化的，就像训练模型参数一样。向量中的每一个数字都是一个可以被微调的连续值。
- **优点和缺点**：它通常比离散提示更高效，因为可以在数学上找到“最优”的提示。但缺点是，这些数字向量对人类来说是**完全不可读、不可解释的**。



**Prompt Tuning（提示调优）**

这是实现软提示最直接的方法之一。

**目标**：让一个通用的LLM（比如GPT）擅长做“情感分类”任务，判断一句话是积极的还是消极的。

**工作流程**：

1. **准备输入**：比如一句话 ` "这部电影太棒了！"`。模型会首先把这句话转换成它内部能理解的数字向量（Embeddings）。

2. **插入“软提示”**：我们**不**在原始文本前加上“请判断情感：”这样的硬提示。而是在转换后的数字向量**前面**，插入几个（比如10个）**可训练的、全新的“虚拟Token”向量**。这些向量一开始是随机初始化的数字。

   ```
   [软提示向量1, 软提示向量2, ..., 软提示向量10]  +  ["这部", "电影", "太棒", "了", "！"]的向量
   ```

3. **冻结大模型，只训练“软提示”**：把上面拼接好的完整向量序列输入给LLM。LLM的**所有内部参数（亿万个）全部保持不变（冻结）**。

4. **计算误差并更新**：模型会输出一个结果（比如“中性”）。我们拿这个结果和正确答案（“积极”）对比，计算出误差。然后，最关键的一步来了：我们用这个误差，通过梯度下降算法，**只去更新前面那10个软提示向量里的数字**。

5. **重复学习**：通过成千上万个例子的反复训练，这10个软提示向量会逐渐被“雕琢”成最优的值。它们最终会变成一组“神奇”的数字，只要把它们加在任何一句话的向量前面，这个被冻结的LLM就会被引导着去执行“情感分类”这个任务。

训练完成后，这组学好的数字向量就是我们的**连续性提示**。它对人类来说没有意义，但对模型来说，是比任何自然语言都更精确的指令。



**Prefix Tuning (前缀调优)**

这是另一种稍有不同的软提示技术，它更加强大。

- **与Prompt Tuning的区别**：Prompt Tuning只在最开始的输入层加入可训练的向量。而Prefix Tuning则更进一步，它会在Transformer模型的**每一层**都加入一小段可训练的前缀向量。
- **效果**：这相当于在模型进行每一步深入思考时，都给它一个“微调”的引导信号。这使得它对生成式任务（比如文章摘要、风格迁移）的控制力更强。

### 5. ==思维树ToT==

```
你好，我需要你扮演一位经验丰富的商业策略顾问。我们将一起使用一个系统性的、分步骤的思考方法，来解决一个商业挑战。这个方法模仿“思维树”，包含多个思考分支的生成、评估和选择。

**# 目标：**
为我即将开业的、预算非常有限的独立咖啡馆，策划出3个最具有性价比的营销策略，以吸引到最初的100名顾客。

**# 思考过程（请严格按照以下步骤执行）：**

**第一步：广泛生成初始想法（生成思考分支）**
* 请先不要直接给我最终答案。
* 首先，请至少 brainstorm 出 6 个不同的、初步的营销想法。
* 请将这些想法以列表形式呈现，每个想法用一句话简要描述。

**第二步：严格评估每个想法（评估分支价值）**
* 接下来，创建一个表格。
* 在表格中，请对你在第一步中提出的每一个想法，从以下四个维度进行打分（1-10分，10分为最优）：
    1.  **成本效益 (Cost-Effectiveness):** 这个想法花钱多吗？分数越高代表花钱越少、效果越好。
    2.  **执行难度 (Ease of Implementation):** 这个想法容易落地执行吗？分数越高代表越容易。
    3.  **目标精准度 (Targeting Accuracy):** 这个想法能精准地触达到咖啡馆周边的潜在顾客吗？分数越高代表越精准。
    4.  **长期价值 (Long-term Value):** 这个想法除了引流，对建立品牌或顾客忠诚度有帮助吗？分数越高代表长期价值越大。
* 在表格的最后一列，请给出一个“综合推荐指数”分数，并简要说明打分理由。

**第三步：选择最优分支并给出理由（剪枝与选择）**
* 根据第二步的评估表格，请选出“综合推荐指数”最高的3个营销策略。
* 请明确告诉我你为什么选择这3个，并简要说明你排除了哪些以及为什么。

**第四步：深化最优策略（探索选定分支）**
* 对于你最终选出的3个策略，请对每一个进行详细的展开说明。
* 内容需要包括具体的执行步骤、可能的预算估算、以及成功的关键点。

请开始你的第一步。
```

### 6. ==思维图GoT==

```
你好，我需要你扮演一位顶级的科技产品创新专家。我们将使用一个高级的、模拟“思维图”（Graph of Thoughts）的思考框架，来构思一款全新的产品。这个框架的核心在于不仅要生成和评估想法，更要将不同的好想法进行融合与创造。

**# 目标：**
构思一款全新的智能硬件产品，旨在解决有小孩（0-5岁）的、忙碌的职场父母的核心痛点。

**# 思考过程（请严格按照以下步骤执行）：**

**第一步：生成初始想法节点（Node Generation）**
* 为了促进后续的融合，请从以下三个不同的领域，分别 brainstorm 至少2个相关的功能或产品点子：
    1.  **智能家居领域：** （例如：环境感知、自动化设备）
    2.  **个人效率工具领域：** （例如：日程管理、专注力辅助）
    3.  **婴幼儿护理领域：** （例如：健康监测、安抚设备）
* 请将这些初始想法清晰地列出来。

**第二步：评估每个想法节点（Node Evaluation）**
* 创建一个表格。
* 在表格中，请对你在第一步中提出的每一个独立想法，从以下三个维度进行打分（1-10分，10分为最优）：
    1.  **痛点解决度 (Problem Solving):** 这个功能对父母来说有多大的实际用处？
    2.  **技术可行性 (Feasibility):** 以当前技术，实现这个功能的难度高吗？（分数越高越容易）
    3.  **创新性 (Originality):** 这个想法有多新颖？
* 在表格最后一列给出一个“潜力分数”。

**第三步：融合与综合想法（Graph Aggregation - 核心步骤）**
* 现在，执行“思维图”最关键的一步：**综合创造**。
* 请仔细审阅第二步中所有“潜力分数”较高的想法，**至少创造出 2 个全新的“融合产品概念”**。
* 每一个“融合产品”都必须是**通过合并2个或以上来自不同领域的初始想法**而诞生的。
* 对于每个融合概念，请明确说明：
    * **融合了哪些初始想法？** (例如：融合了“智能家居A”和“婴幼儿护理B”)
    * **产生的协同效应是什么？** (即 1+1>2 的效果是什么？)
    * 为这个新概念起一个名字。

**第四步：细化与完善最优融合概念（Path Refinement）**
* 请对你在第三步中创造的几个“融合产品概念”进行一次快速的最终评估。
* 选择你认为最具有市场潜力的那一个。
* 最后，为这个最终概念提供一份详细的产品简介，包括：
    * 核心功能列表
    * 目标用户画像
    * 一句有吸引力的营销口号

请开始你的第一步。
```

**思维树:** 像一棵树，从一个根节点出发，不断向下生出分支。每个分支独立发展，**分支之间不会重新连接**。它擅长**探索和选择**最佳路径。

**思维图 :** 像一张关系网。它不仅可以像树一样分叉探索，更重要的是，它允许**不同的思考节点（想法）之间进行合并、融合和转换**。两个来自不同思考分支的好想法可以被结合起来，创造出一个全新的、更强大的想法。它擅长**探索、选择和综合创造**。

### 7. ==ReAct==

**ReAct 框架就是让 AI 模型模仿“思考 -> 行动 -> 观察”的循环过程。**

它的名字本身就是两个核心单词的结合：

- **Re**ason (推理/思考)
- **Act** (行动/执行)



**思维链/树/图 (CoT/ToT/GoT):** 主要关注如何**优化AI的内部思考和推理结构**，让它想得更深、更广。

**ReAct:** 关注如何让AI的思考**与外部世界互动起来**，让它不仅能想，还能查、能算、能动手，成为一个真正的“行动者”。



要赋予LLM ReAct能力的三个核心要素：

- LLM（需要格式化输出）
- functions/API
- **编排器**（LangChain/LlamaIndex）

### 8. ==阐述Instruct Tunning和Prompt Learning的区别==

Instruction tuning 是通过微调模型使其适应特定指令,而prompt learning 则通过设计提示词来直接引
导模型输出。在数据需求上,Instruction tuning 需要大量的标注数据进行训练,而prompt learning 更依赖于
提示词的设计,不需要重新训练模型。

### 9. ==阐述 CoT 和 Instruct Tunning==

链式思维提示通过在prompt中引入中间推理步骤,启发了模型的复杂推理能力。

Instruction Tuning（SFT）是一种通过在由(指令,输出)对组成的数据集上进一步训练LLMs的过程。

### 10. ==ICL（in-Context Learning）没有改变权重，但为什么有效？==

简单来说，ICL（In-Context Learning，情境学习）之所以有效，是因为大模型在它那庞大到难以想象的预训练过程中，**已经学会了“如何学习”**，或者更准确地说，**学会了“如何识别并遵循模式”**。

ICL没有改变权重，但它在模型的**一次前向计算（Forward Pass）中**，通过**注意力机制**，动态地改变了信息的处理流，从而引导模型输出你想要的结果。

大模型中的自注意力机制允许模型在输入中捕捉长距离的依赖关系和上下文信息。这意味着模型能够**识别并记住**输入序列中的重要信息,并在生成输出时**参考**这些信息。这种机制使得模型能够在不调整权重的情况下,依赖上下文示例进行有效推理。

### 11. ==LlamaIndex和LangChain==

| 特性       | LlamaIndex                                                 | LangChain                                                    |
| ---------- | ---------------------------------------------------------- | ------------------------------------------------------------ |
| 核心焦点   | 数据框架 (Data Framework)                                  | 通用框架 (General Framework)                                 |
| 最擅长的事 | RAG (检索增强生成)                                         | 智能代理 (Agents) 与工具调用                                 |
| 核心优势   | 对数据的索引、检索、转换和查询提供了极其丰富和深入的优化。 | 拥有强大的链（Chains）和代理执行器（AgentExecutor）逻辑，擅长编排复杂的任务流。 |
| 比喻       | 顶级图书管理员/数据专家                                    | 全能项目经理/总指挥                                          |

它们可以一起使用：

LangChain Agent 负责接收用户任务，进行思考和规划（ReAct）。

当 Agent 的“思考”步骤发现需要查询内部知识库时，它就会调用 LlamaIndex 这个“工具”。

LlamaIndex 高效地完成检索和答案合成，并将结果返回给 LangChain Agent。

Agent 再根据 LlamaIndex 返回的结果，进行下一步的思考或行动。